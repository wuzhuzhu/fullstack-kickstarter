import type { NextApiRequest, NextApiResponse } from 'next'
import { getSession } from 'next-auth/react';
import openai from '../../../lib/openai';
import { DEFAULT_OPENAI_PARAMS, QUESTION_PREFIX } from '../../../lib/utils/config';
import type { CreateCompletionRequest, CreateCompletionResponse } from 'openai'
import { PromptConfig } from '../../../lib/types/basic'
import { copyFile } from 'fs';

interface IGeneratePromptParams {
  text: string
  prevQuestions: string[]
  config?: PromptConfig
}

const defaultConfig: PromptConfig = {
  knowledgeDomain: 'frontend',
  language: 'zh-CN',
  programmingLanguage: 'javascript',
  framework: 'react'
}

const generateGetQuestionsPrompt = ({ text, prevQuestions = [], config = defaultConfig }: IGeneratePromptParams) => {
  const prompt = `
  Task description: This is the content recognized from the audio clip. You need to strictly follow the 6 requirements below to process this text into a list of questions.
  1,Remove meaningless and non-${config.knowledgeDomain} related parts, correct potential speech recognition errors
  2,Questions translated into: ${config.language}. Eliminate duplicate questions
  3,Result must not include: ${prevQuestions?.length && prevQuestions.join('; ')}
  4,Format: Each question should occupy one line, start with ${QUESTION_PREFIX}, and end with a line break. 
  Make sure that the internal content of each question does not contain the beginning and end identifiers.
  Examples:
  è¾“å…¥ï¼š
  ä¾‹instance,ä½†æ˜¯æ°¸è¿œä¹Ÿä¸è¦éœ€è¦ç›´æŽ¥åˆ›é€ ä¸€ä¸ªç»„ä»¶å®žä¾‹ï¼Œå› ä¸ºreactå¸®æˆ‘ä»¬åšäº†è¿™ã€‚8, Ract æ© create classå’Œextends conponentsçš„ï¼Œå°±æ˜¯ç®€è¦å›žç­”ä¸‹ä»–ä¿©çš„ï¼ŒåŒºåˆ«æœ‰å“ªäº›ï¼Ÿæµè§ˆå™¨çš„æ¸²æŸ“åŽŸç†ï¼Ÿ
  å›žç­”ï¼š
  ${QUESTION_PREFIX} React.createClasså’Œ extends Componentsçš„åŒºåˆ«æœ‰å“ªäº›ï¼Ÿ
  ${QUESTION_PREFIX} æµè§ˆå™¨çš„æ¸²æŸ“åŽŸç†ï¼Ÿ
  è¾“å…¥ï¼š
  å¼€å‘æœºå˜›ï¼Ÿfdasjlï¼ŒåŽç«¯å¤§ä½¬å¸Œæœ›å–œæ¬¢ðŸ˜ä¸‹ç­åšä»€ä¹ˆï¼Ÿ
  å›žç­”ï¼š
  ${QUESTION_PREFIX} Null
  è¾“å…¥ï¼š${text}
  å›žç­”ï¼š
  `
  return prompt
}

export default async function getQuestions(req: NextApiRequest, res: NextApiResponse) {
  const session = await getSession({ req })
  const { text, prevQuestions } = req.body
  console.log('text from voice recognition', text)
  if (session) {
    try {
      const response = await openai.createCompletion({
        ...DEFAULT_OPENAI_PARAMS,
        prompt: generateGetQuestionsPrompt({ text, prevQuestions }),
      });
      console.log(response?.data?.choices?.[0]?.text)
      const questions = response?.data?.choices?.[0]?.text?.split('\n')
        .map(item => item.trim())
        .filter((item) => item.startsWith(QUESTION_PREFIX))
        .map(item => item.replace(QUESTION_PREFIX, ''))
      res.status(200).json({ message: 'OK', questions })
    } catch (e) {
      console.error('error', e.message)
    }
  } else {
    res.status(401).send({ message: 'Unauthorized' })
  }
}